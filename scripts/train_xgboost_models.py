#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Train XGBoost Models for All Leagues

This script trains XGBoost models to replace the current Stacking Ensemble models.
Expected improvement: +3% winner accuracy, -1.5 points margin error.

Usage:
    python scripts/train_xgboost_models.py [--league-id LEAGUE_ID] [--all-leagues]
"""

import sqlite3
import os
import sys
import json
import pickle
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import numpy as np
import pandas as pd

# Fix encoding for Windows console
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("‚ùå XGBoost not installed. Install with: pip install xgboost")
    sys.exit(1)

from prediction.config import LEAGUE_MAPPINGS
from prediction.features import build_feature_table, FeatureConfig
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict
from sklearn.metrics import accuracy_score, mean_absolute_error, classification_report

def load_data(conn: sqlite3.Connection, league_id: int, config: FeatureConfig) -> pd.DataFrame:
    """Load and prepare training data for a league"""
    print(f"üìä Loading data for league {league_id}...")
    
    # Build feature table
    df = build_feature_table(conn, config)
    
    # Filter by league
    df_league = df[df['league_id'] == league_id].copy()
    
    # Only use games with scores (completed games)
    df_league = df_league[
        df_league['home_score'].notna() & 
        df_league['away_score'].notna()
    ].copy()
    
    print(f"   Found {len(df_league)} completed games")
    
    if len(df_league) < 20:
        print(f"   ‚ö†Ô∏è  Not enough games (need at least 20)")
        return None
    
    return df_league

def prepare_features_and_targets(df: pd.DataFrame) -> tuple:
    """Prepare features and targets for training"""
    # Feature columns (exclude target columns and IDs)
    exclude_cols = [
        'event_id', 'league_id', 'season', 'date_event', 
        'home_team_id', 'away_team_id',
        'home_score', 'away_score', 'home_win', 'draw'
    ]
    
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    # Remove any columns with all NaN
    feature_cols = [col for col in feature_cols if not df[col].isna().all()]
    
    # Prepare feature matrix
    X = df[feature_cols].fillna(0).values
    
    # Targets
    # 1. Winner classification (home_win: 1 = home wins, 0 = away wins/draw)
    y_winner = (df['home_score'] > df['away_score']).astype(int).values
    
    # 2. Home score regression
    y_home_score = df['home_score'].values
    
    # 3. Away score regression
    y_away_score = df['away_score'].values
    
    return X, y_winner, y_home_score, y_away_score, feature_cols

def train_xgboost_models(X: np.ndarray, y_winner: np.ndarray, 
                         y_home_score: np.ndarray, y_away_score: np.ndarray,
                         feature_cols: List[str], use_all_data: bool = True) -> Dict[str, Any]:
    """Train XGBoost models for winner prediction and score prediction
    
    Args:
        use_all_data: If True, train on all data and use cross-validation for evaluation.
                     If False, use 80/20 train/test split.
    """
    print(f"ü§ñ Training XGBoost models...")
    
    if use_all_data and len(X) >= 50:
        # Use all data for training, evaluate with cross-validation
        print(f"   Using all {len(X)} games for training (cross-validation for evaluation)")
        
        # 1. Winner Classifier (XGBoost)
        print(f"   Training winner classifier...")
        clf = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='logloss'
        )
        clf.fit(X, y_winner)
        
        # Evaluate with cross-validation (5-fold)
        cv_scores = cross_val_score(clf, X, y_winner, cv=5, scoring='accuracy')
        winner_accuracy = cv_scores.mean()
        print(f"   ‚úÖ Winner accuracy (CV): {winner_accuracy:.1%} (¬±{cv_scores.std():.1%})")
        
        # 2. Home Score Regressor (XGBoost)
        print(f"   Training home score regressor...")
        reg_home = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mae'
        )
        reg_home.fit(X, y_home_score)
        
        # Evaluate with cross-validation
        y_home_pred_cv = cross_val_predict(reg_home, X, y_home_score, cv=5)
        home_mae = mean_absolute_error(y_home_score, y_home_pred_cv)
        print(f"   ‚úÖ Home score MAE (CV): {home_mae:.2f} points")
        
        # 3. Away Score Regressor (XGBoost)
        print(f"   Training away score regressor...")
        reg_away = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mae'
        )
        reg_away.fit(X, y_away_score)
        
        # Evaluate with cross-validation
        y_away_pred_cv = cross_val_predict(reg_away, X, y_away_score, cv=5)
        away_mae = mean_absolute_error(y_away_score, y_away_pred_cv)
        print(f"   ‚úÖ Away score MAE (CV): {away_mae:.2f} points")
        
        overall_mae = (home_mae + away_mae) / 2
        
        return {
            'models': {
                'clf': clf,
                'reg_home': reg_home,
                'reg_away': reg_away
            },
            'feature_columns': feature_cols,
            'performance': {
                'winner_accuracy': winner_accuracy,
                'home_mae': home_mae,
                'away_mae': away_mae,
                'overall_mae': overall_mae
            },
            'training_games': len(X),
            'test_games': 0
        }
    else:
        # Use train/test split (original behavior)
        # Split data
        X_train, X_test, y_winner_train, y_winner_test, \
        y_home_train, y_home_test, y_away_train, y_away_test = train_test_split(
            X, y_winner, y_home_score, y_away_score,
            test_size=0.2, random_state=42, stratify=y_winner
        )
        
        print(f"   Training set: {len(X_train)} games")
        print(f"   Test set: {len(X_test)} games")
        
        # 1. Winner Classifier (XGBoost)
        print(f"   Training winner classifier...")
        clf = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='logloss'
        )
        clf.fit(X_train, y_winner_train)
        
        # Evaluate classifier
        y_winner_pred = clf.predict(X_test)
        winner_accuracy = accuracy_score(y_winner_test, y_winner_pred)
        print(f"   ‚úÖ Winner accuracy: {winner_accuracy:.1%}")
        
        # 2. Home Score Regressor (XGBoost)
        print(f"   Training home score regressor...")
        reg_home = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mae'
        )
        reg_home.fit(X_train, y_home_train)
        
        # Evaluate home regressor
        y_home_pred = reg_home.predict(X_test)
        home_mae = mean_absolute_error(y_home_test, y_home_pred)
        print(f"   ‚úÖ Home score MAE: {home_mae:.2f} points")
        
        # 3. Away Score Regressor (XGBoost)
        print(f"   Training away score regressor...")
        reg_away = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mae'
        )
        reg_away.fit(X_train, y_away_train)
        
        # Evaluate away regressor
        y_away_pred = reg_away.predict(X_test)
        away_mae = mean_absolute_error(y_away_test, y_away_pred)
        print(f"   ‚úÖ Away score MAE: {away_mae:.2f} points")
        
        overall_mae = (home_mae + away_mae) / 2
        
        return {
            'models': {
                'clf': clf,
                'reg_home': reg_home,
                'reg_away': reg_away
            },
            'feature_columns': feature_cols,
            'performance': {
                'winner_accuracy': winner_accuracy,
                'home_mae': home_mae,
                'away_mae': away_mae,
                'overall_mae': overall_mae
            },
            'training_games': len(X_train),
            'test_games': len(X_test)
        }

def save_model(model_data: Dict[str, Any], league_id: int, league_name: str, 
               output_dir: str = 'artifacts') -> str:
    """Save trained model to file"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # Add metadata
    model_data['league_id'] = league_id
    model_data['league_name'] = league_name
    model_data['model_type'] = 'xgboost'
    model_data['trained_at'] = datetime.now().isoformat()
    
    # Save model
    model_file = output_path / f'league_{league_id}_model_xgboost.pkl'
    with open(model_file, 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"üíæ Saved model to: {model_file}")
    return str(model_file)

def update_registry(league_id: int, league_name: str, model_data: Dict[str, Any],
                   registry_path: str = 'artifacts/model_registry.json'):
    """Update model registry with new model info"""
    registry_path = Path(registry_path)
    
    # Load existing registry
    if registry_path.exists():
        with open(registry_path, 'r') as f:
            registry = json.load(f)
    else:
        registry = {
            'last_updated': datetime.now().isoformat(),
            'leagues': {}
        }
    
    # Update league entry
    if 'leagues' not in registry:
        registry['leagues'] = {}
    
    registry['leagues'][str(league_id)] = {
        'name': league_name,
        'trained_at': model_data['trained_at'],
        'training_games': model_data['training_games'],
        'model_type': 'xgboost',
        'performance': model_data['performance']
    }
    
    registry['last_updated'] = datetime.now().isoformat()
    
    # Save registry
    with open(registry_path, 'w') as f:
        json.dump(registry, f, indent=2)
    
    print(f"üìù Updated registry: {registry_path}")

def train_league(league_id: int, league_name: str, db_path: str) -> bool:
    """Train XGBoost models for a single league"""
    print(f"\n{'='*80}")
    print(f"Training XGBoost Model: {league_name} (ID: {league_id})")
    print(f"{'='*80}")
    
    try:
        # Connect to database
        conn = sqlite3.connect(db_path)
        
        # Configure features (neutral mode for Rugby World Cup and Six Nations)
        config = FeatureConfig(
            elo_priors=None,
            elo_k=24.0,
            neutral_mode=(league_id == 4574 or league_id == 4714)  # Rugby World Cup and Six Nations
        )
        
        # Load data
        df = load_data(conn, league_id, config)
        if df is None:
            conn.close()
            return False
        
        # Prepare features and targets
        X, y_winner, y_home_score, y_away_score, feature_cols = prepare_features_and_targets(df)
        
        # Train models (use all data for training when we have enough games)
        model_data = train_xgboost_models(X, y_winner, y_home_score, y_away_score, feature_cols, use_all_data=True)
        
        # Save model
        model_file = save_model(model_data, league_id, league_name)
        
        # Update registry
        update_registry(league_id, league_name, model_data)
        
        conn.close()
        
        print(f"‚úÖ Successfully trained XGBoost model for {league_name}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error training {league_name}: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_total_games(db_path: str, min_games: int = 900) -> Tuple[bool, int]:
    """Check if total completed games across all leagues meets minimum threshold"""
    conn = sqlite3.connect(db_path)
    
    try:
        # Count total completed games (with scores) across all leagues
        cursor = conn.execute("""
            SELECT COUNT(*) 
            FROM event 
            WHERE home_score IS NOT NULL 
            AND away_score IS NOT NULL
            AND league_id IN ({})
        """.format(','.join(map(str, LEAGUE_MAPPINGS.keys()))))
        
        total_games = cursor.fetchone()[0]
        meets_threshold = total_games >= min_games
        
        return meets_threshold, total_games
    finally:
        conn.close()

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='Train XGBoost models for rugby prediction')
    parser.add_argument('--league-id', type=int, help='Train specific league ID')
    parser.add_argument('--all-leagues', action='store_true', help='Train all leagues')
    parser.add_argument('--db-path', type=str, default=None, help='Path to database')
    parser.add_argument('--min-total-games', type=int, default=900, 
                       help='Minimum total games required before training (default: 900)')
    parser.add_argument('--skip-game-check', action='store_true',
                       help='Skip the total games check and train anyway')
    
    args = parser.parse_args()
    
    # Find database
    if args.db_path:
        db_path = args.db_path
    else:
        db_path = Path(__file__).parent.parent / 'data.sqlite'
        if not db_path.exists():
            db_path = Path(__file__).parent.parent / 'rugby-ai-predictor' / 'data.sqlite'
    
    if not db_path.exists():
        print(f"‚ùå Database not found at {db_path}")
        sys.exit(1)
    
    print(f"üìÅ Using database: {db_path}")
    
    # Check total games threshold (unless explicitly skipped)
    if not args.skip_game_check and args.all_leagues:
        print(f"\nüîç Checking total games threshold ({args.min_total_games}+ games required)...")
        meets_threshold, total_games = check_total_games(str(db_path), args.min_total_games)
        
        print(f"   Total completed games: {total_games}")
        
        if not meets_threshold:
            print(f"   ‚ö†Ô∏è  Total games ({total_games}) is below threshold ({args.min_total_games})")
            print(f"   ‚ùå Not enough data to train XGBoost models. Need {args.min_total_games - total_games} more games.")
            print(f"   üí° Use --skip-game-check to train anyway")
            sys.exit(1)
        
        print(f"   ‚úÖ Total games ({total_games}) meets threshold ({args.min_total_games}+) - proceeding with XGBoost training")
    
    # Determine which leagues to train
    if args.league_id:
        if args.league_id not in LEAGUE_MAPPINGS:
            print(f"‚ùå League ID {args.league_id} not found in LEAGUE_MAPPINGS")
            sys.exit(1)
        leagues_to_train = [(args.league_id, LEAGUE_MAPPINGS[args.league_id])]
    elif args.all_leagues:
        leagues_to_train = list(LEAGUE_MAPPINGS.items())
    else:
        print("‚ùå Please specify --league-id or --all-leagues")
        parser.print_help()
        sys.exit(1)
    
    # Train models
    print(f"\nüöÄ Training XGBoost models for {len(leagues_to_train)} league(s)...")
    print(f"   Expected improvement: +3% winner accuracy, -1.5 points margin error")
    
    success_count = 0
    for league_id, league_name in leagues_to_train:
        if train_league(league_id, league_name, str(db_path)):
            success_count += 1
    
    print(f"\n{'='*80}")
    print(f"‚úÖ Training complete!")
    print(f"   Successfully trained: {success_count}/{len(leagues_to_train)} leagues")
    print(f"{'='*80}")
    
    if success_count < len(leagues_to_train):
        print(f"\n‚ö†Ô∏è  Some leagues failed to train. Check errors above.")
        sys.exit(1)

if __name__ == "__main__":
    main()

